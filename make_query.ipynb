{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['absolute', 'agent', 'amazon', 'atomic', 'balance', 'band', 'bar', 'bark', 'base', 'basis', 'battery', 'beam', 'beat', 'bench', 'block', 'board', 'bolt', 'bond', 'buffer', 'bug', 'capital', 'carrier', 'case', 'cell', 'center', 'channel', 'character', 'charge', 'check', 'circuit', 'class', 'clean', 'clip', 'cluster', 'clustering', 'complex', 'compound', 'conductor', 'console', 'control', 'core', 'corner', 'corpus', 'crack', 'crane', 'crash', 'criterion', 'current', 'cycle', 'date', 'deck', 'deduction', 'delta', 'depth', 'development', 'dial', 'domain', 'dot', 'draft', 'drift', 'elasticity', 'element', 'emission', 'ensemble', 'feature', 'field', 'file', 'filter', 'flow', 'focus', 'frame', 'fusion', 'graph', 'grid', 'ground', 'horn', 'hull', 'identity', 'kernel', 'key', 'layer', 'left', 'line', 'link', 'localization', 'mark', 'market', 'master', 'matrix', 'medium', 'mint', 'mode', 'mole', 'nail', 'needle', 'net', 'network', 'node', 'norm', 'note', 'object', 'organic', 'pad', 'palm', 'panel', 'patch', 'period', 'phoenix', 'pitch', 'plane', 'plate', 'plot', 'point', 'pool', 'portfolio', 'post', 'pot', 'pound', 'power', 'probe', 'protocol', 'queue', 'race', 'rack', 'radical', 'range', 'recognition', 'regression', 'representation', 'resolution', 'reward', 'ring', 'rock', 'rod', 'roll', 'round', 'scale', 'scope', 'seal', 'segmentation', 'sell', 'server', 'service', 'set', 'sheet', 'show', 'sketch', 'solution', 'spring', 'stake', 'state', 'stem', 'strain', 'stress', 'strike', 'swift', 'tablet', 'tag', 'tap', 'terminal', 'thread', 'tie', 'tissue', 'tone', 'unity', 'value', 'vector', 'vision', 'warrant', 'web', 'yield', 'yolo'])\n"
     ]
    }
   ],
   "source": [
    "json_file_path = './data/polyseme_wiki.json'\n",
    "\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    polyseme_wiki = json.load(json_file)\n",
    "\n",
    "print(polyseme_wiki.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "OPENAI_API_KEY = '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'\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "model = \"gpt-3.5-turbo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Query Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_query = 3\n",
    "\n",
    "data = {}\n",
    "save_json_path = './data/gpt_query.json'\n",
    "\n",
    "for polyseme in polyseme_wiki.keys():\n",
    "    prompt_ex = \"A polyseme 'cluster' has several meanings. An ambiguous query and the corresponding answer for the polyseme could be Q1. What are the tools and software used for cluster analysis?\"\n",
    "    prompt1 = \"A polyseme '{}' could have several meanings as following\".format(polyseme)\n",
    "    prompt2 = ''\n",
    "    for i, val in enumerate(polyseme_wiki[polyseme]):\n",
    "        prompt2 += '{}. {}.\\n'.format(i+1, val)\n",
    "    prompt3 = \"Make {} ambiguous queries that could have different answers related to the word '{}'. The query should contain the word '{}'. Give me in the format of numbering 1., 2., 3.\".format(num_query, polyseme, polyseme)\n",
    "\n",
    "    prompt = prompt1 + '\\n' + prompt2 + '\\n' + prompt3\n",
    "\n",
    "\n",
    "    # ChatGPT API \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    )\n",
    "    answer = response['choices'][0]['message']['content']\n",
    "\n",
    "    paraphrased_q = []\n",
    "    for i in range(num_paraphrase):\n",
    "        try:\n",
    "            try:\n",
    "                tmp = answer.split('{}.'.format(i+1))[1]\n",
    "                tmp = tmp.split('.')[0].strip()\n",
    "                paraphrased_q.append(tmp)\n",
    "            except:\n",
    "                tmp = answer.split('{})'.format(i+1))[1]\n",
    "                tmp = tmp.split('.')[0].strip()\n",
    "                paraphrased_q.append(tmp)                \n",
    "        except:\n",
    "            print(answer)\n",
    "    \n",
    "    data[ind] = paraphrased_q\n",
    "\n",
    "with open(save_json_path, 'w') as f:\n",
    "    json.dump(data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Answer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-21",
   "language": "python",
   "name": "deep-learning-21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
